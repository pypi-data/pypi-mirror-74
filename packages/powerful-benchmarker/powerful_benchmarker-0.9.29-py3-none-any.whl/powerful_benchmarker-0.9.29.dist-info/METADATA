Metadata-Version: 2.1
Name: powerful-benchmarker
Version: 0.9.29
Summary: A highly-configurable tool that enables thorough evaluation of deep metric learning algorithms. 
Home-page: https://github.com/KevinMusgrave/powerful-benchmarker
Author: Kevin Musgrave
Author-email: tkm45@cornell.edu
License: UNKNOWN
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.0
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: scikit-learn
Requires-Dist: torch
Requires-Dist: torchvision
Requires-Dist: easy-module-attribute-getter (==0.9.39)
Requires-Dist: record-keeper (==0.9.27)
Requires-Dist: tensorboard
Requires-Dist: matplotlib
Requires-Dist: pretrainedmodels
Requires-Dist: pytorch-metric-learning (==0.9.88)
Requires-Dist: pandas
Requires-Dist: ax-platform
Requires-Dist: faiss-gpu

<h1 align="center">
 Powerful Benchmarker
</h2>
<p align="center">

</h2>
<p align="center">
 <a href="https://badge.fury.io/py/powerful-benchmarker">
     <img alt="PyPi version" src="https://badge.fury.io/py/powerful-benchmarker.svg">
 </a>


## Documentation
[**View the documentation here**](https://kevinmusgrave.github.io/powerful-benchmarker/)

## A Metric Learning Reality Check
This library was used for [A Metric Learning Reality Check](https://arxiv.org/abs/2003.08505). See [the documentation](https://kevinmusgrave.github.io/powerful-benchmarker/papers/mlrc) for supplementary material.

## Benchmark results: 
- [4-fold cross validation, test on 2nd-half of classes](https://docs.google.com/spreadsheets/d/1brUBishNxmld-KLDAJewIc43A4EVZk3gY6yKe8OIKbY/edit?usp=sharing)

## Benefits of this library
1. Highly configurable
    - Use the default configs files, merge in your own, or override options via the command line.
2. Extensive logging
    - View experiment data in tensorboard, csv, and sqlite format.
3. Easy hyperparameter optimization
    - Simply append \~BAYESIAN\~ to the hyperparameters you want to optimize.
4. Customizable
    - Benchmark your own losses, miners, datasets etc. with a simple function call.

## Installation
```
pip install powerful-benchmarker
```

## Citing the benchmark results
If you'd like to cite the benchmark results, please cite this paper:
```latex
@misc{musgrave2020metric,
    title={A Metric Learning Reality Check},
    author={Kevin Musgrave and Serge Belongie and Ser-Nam Lim},
    year={2020},
    eprint={2003.08505},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```

## Citing the code
If you'd like to cite the powerful-benchmarker code, you can use this bibtex:
```latex
@misc{Musgrave2019,
  author = {Musgrave, Kevin and Lim, Ser-Nam and Belongie, Serge},
  title = {Powerful Benchmarker},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/KevinMusgrave/powerful-benchmarker}},
}
```

## Acknowledgements
Thank you to Ser-Nam Lim at Facebook AI, and my research advisor, Professor Serge Belongie. This project began during my internship at Facebook AI where I received valuable feedback from Ser-Nam, and his team of computer vision and machine learning engineers and research scientists.


