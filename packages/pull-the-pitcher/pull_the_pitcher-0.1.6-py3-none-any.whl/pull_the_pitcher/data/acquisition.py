# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/00_data_acquisition.ipynb (unless otherwise specified).

__all__ = ['load_postgres_env', 'load_postgres_engine', 'query_statcast', 'query_db']

# Internal Cell
from pybaseball import statcast
import pandas as pd
from fastscript import *
from sqlalchemy import create_engine
from os import path
import os
from dotenv import find_dotenv, load_dotenv

# Cell

def load_postgres_env():
    # retrieving engironment variables
    load_dotenv(find_dotenv(), override=True)
    dbname = os.getenv("POSTGRES_DB")
    user = os.getenv("POSTGRES_USER")
    password = os.getenv("POSTGRES_PASSWORD")
    host = os.getenv("POSTGRES_HOST")
    port = os.getenv("POSTGRES_PORT")
    return dbname, user, password, host, port

def load_postgres_engine():
    # postgres env variables
    dbname, user, password, host, port = load_postgres_env()

    # creating remote db connection
    engine = create_engine(f'postgresql://{user}:{password}@{host}/{dbname}')

    return engine

# Cell


@call_parse
def query_statcast(
    start_dt: Param(help="Beginning date to pull data from", type=str) = None,
    end_dt: Param(help="End date to pull data from", type=str) = None,
    team: Param(help="Abbreviation for team of interest", type=str) = None,
    verbose: Param(
        help="Whether or not to print verbose updates", type=bool_arg
    ) = True,
    if_exists: Param(
        help="How to behave if the table already exists.",
        type=str,
    ) = 'fail'
):
    """
    Callable from the command-line or in Python. Pulls pitch-level MLB data from [statcast](https://baseballsavant.mlb.com/statcast_search).
    Saves to a pre-instantiated Postgres DB in AWS RDS.

    * inputs:
        - `start_dt`: `str`, Beginning date to pull data from = None
        - `end_dt`: `str`, End date to pull data from = None
        - `team`: `str`, abbreviation for team of interest = None
        - `verbose`: `bool`, Whether or not to print verbose updates
        - `if_exists`: `str`, How to behave if the table already exists.
            * `'fail'`: Raise a ValueError.
            * `'replace'`: Drop the table before inserting new values.
            * `'append'`: Insert new values to the existing table.

    * outputs:
        - None
    """
    # creating remote db connection
    engine = load_postgres_engine()

    # pulling data from statcast
    data = statcast(start_dt=start_dt, end_dt=end_dt, team=team, verbose=verbose)
    with engine.connect() as connection:
        data.to_sql(f"statcast_{start_dt[:4]}", connection, if_exists=if_exists)

    return None


# Cell


def query_db(
    year: str = "2019",
    columns: str = "*",
    limit: int = None,
    verbose: bool = True,
):
    """
    Queries a sqlite db file. Assumes that it's been created by `query_statcast`.
    Only queries for a single year at a time.

    * intputs:
        - `year`: `str`, year of data to query
        - `columns`: `str`, which columns from the [statcast data](https://baseballsavant.mlb.com/csv-docs) to include in table
        - `limit`: `int`, the maximum number of rows to retrieve ([postgresql documentation](https://www.postgresql.org/docs/8.1/queries-limit.html))
        - `verbose`: `bool`, Whether or not to print verbose updates

    * output:
        - `df`: `pd.DataFrame`, DataFrame populated with data queried from database
    """
    if verbose:
        print(f"querying year {year} from db now.")

    engine = load_postgres_engine()

    query = f"""select {columns}
                from statcast_{year}"""
    if limit:
        query += f" limit {round(limit)}"

    # if year is not in db, return empty pd.DataFrame
    try:
        with engine.connect() as connection:
            df = pd.read_sql_query(query, connection)
    except:
        print(f"Year {year} not in database. Returning empty dataframe.")
        df = pd.DataFrame()

    return df
