var keras=keras||{},base=base||require("./base"),long=long||{Long:require("long")};keras.ModelFactory=class{match(t){const e=t.identifier,s=e.split(".").pop().toLowerCase();if("h5"===s||"hd5"===s||"hdf5"===s||"keras"===s||"model"===s||"pb"==s||"pth"==s){const e=t.buffer,s=[137,72,68,70,13,10,26,10];return e&&e.length>s.length&&s.every((t,s)=>t===e[s])}if("json"==s&&!e.endsWith("-symbol.json")){const e=t.text;if(-1==e.indexOf('"mxnet_version":',0))try{let t=keras.JsonParser.parse(e);if(t&&t.nodes&&t.arg_nodes&&t.heads)return!1;if(t&&t.modelTopology&&(t=t.modelTopology),t&&t.model_config&&(t=t.model_config),t&&t.class_name)return!0}catch(t){}}return!1}open(t,e){return e.require("./hdf5").then(s=>{let n="Keras",r="",i="",a=null,o=null;const h=t.identifier,u=new keras.Weights;try{switch(h.split(".").pop().toLowerCase()){case"keras":case"h5":case"hd5":case"hdf5":case"model":case"pb":case"pth":if(o=new s.File(t.buffer).rootGroup,o.attribute("model_config")||o.attribute("layer_names")){const t=o.attribute("model_config");t&&(a=keras.JsonParser.parse(t)),i=o.attribute("backend")||"";const e=o.attribute("keras_version")||"";n+=e?" v"+e:"";let s=o.group("model_weights");if(!s&&o.attribute("layer_names")&&(s=o),s){s=new keras.Group(s);for(const t of s.attribute("layer_names")){const e=s.group(t);if(e){const s=e.attribute("weight_names");if(s&&s.length>0)for(const n of s){const s=e.group(n);if(s&&s.value){const e=s.value,r=new keras.Tensor(n,e.type,e.shape,e.littleEndian,e.data,"");if(a)u.add(t,r);else{const e=n.split("/");e.pop();const s=0==e.length||e[0]!==t?[t].concat(e).join("/"):e.join("/");u.add(s,r)}}}}}}}else{if(0!==Object.keys(o.attributes).length||null!==o.value)throw new keras.Error("File format is not HDF5 Weights");if(n="HDF5 Weights",0===Object.keys(o.attributes).length&&null===o.value&&1==o.groups.length&&o.groups[0]&&0===Object.keys(o.groups[0].attributes).length&&null===o.groups[0].value&&(o=o.groups[0]),o.groups.every(t=>0===Object.keys(t.attributes).length&&0==t.groups.length&&null!==t.value))for(const t of o.groups){const e=t.value,s=new keras.Tensor(t.name,e.type,e.shape,e.littleEndian,"string"===e.type?e.value:e.data);u.add("",s)}else if(o.groups.every(t=>0===Object.keys(t.attributes).length&&null===t.value))for(const t of o.groups){const e=t.attributes.name||t.name;for(const s of t.groups){if(0!==Object.keys(s.attributes).length||0!==s.groups.length)throw new keras.Error("Group format is not HDF5 tensor variable.");const t=s.value;if(!t)throw new keras.Error("Variable value is not HDF5 tensor.");const n=e?[e,s.name].join("/"):e.name,r=new keras.Tensor(n,t.type,t.shape,t.littleEndian,"string"===t.type?t.value:t.data);u.add(e,r)}}else{if(!o.groups.every(t=>null===t.value&&t.groups.every(t=>0===Object.keys(t.attributes).length&&null!==t.value)))throw new keras.Error("Module group format is not HDF5 Weights");for(const t of o.groups){const e=t.attributes.name||t.name;for(const s of t.groups){if(0!==Object.keys(s.attributes).length||0!==s.groups.length)throw new keras.Error("Variable format is not HDF5 Weights");const t=s.value;if(!t)throw new keras.Error("Variable value is not HDF5 Weights");const n=e?[e,s.name].join("/"):e.name,r=new keras.Tensor(n,t.type,t.shape,t.littleEndian,"string"===t.type?t.value:t.data);u.add(e,r)}}}}break;case"json":if(a=keras.JsonParser.parse(t.text),a.keras_version){const t=a.keras_version;n+=t?" v"+t:""}if(a.backend&&(i=a.backend),a&&a.modelTopology){i=a.modelTopology.backend;const t=a.modelTopology.keras_version;if(n+=t?" v"+t:"",n="TensorFlow.js "+(a.format?a.format:n),r=a.convertedBy||a.generatedBy||"",a.weightsManifest)for(const t of a.weightsManifest)for(const e of t.weights){const s=new keras.Tensor(e.name,e.dtype,e.shape,!1,null,t.paths.join(";"));u.add("",s)}a=a.modelTopology}a.model_config&&(a=a.model_config)}}catch(t){const e=t&&t.message?t.message:t.toString();throw new keras.Error(e.replace(/\.$/,"")+" in '"+h+"'.")}if(!o&&!a)throw new keras.Error("'model_config' is not present.");if(!o&&!a.class_name)throw new keras.Error("'class_name' is not present.");return keras.Metadata.open(e).then(t=>{try{return new keras.Model(t,n,r,i,a,u)}catch(t){e.exception(t,!1);const s=t&&t.message?t.message:t.toString();throw new keras.Error(s.replace(/\.$/,"")+" in '"+h+"'.")}})})}},keras.Model=class{constructor(t,e,s,n,r,i){this._format=e,this._backend=n,this._producer=s,this._graphs=[new keras.Graph(t,r,i)]}get name(){return null}get description(){return null}get format(){return this._format}get producer(){return this._producer}get runtime(){return this._backend}get graphs(){return this._graphs}},keras.Graph=class{constructor(t,e,s){if(this._metadata=t,this._inputs=[],this._outputs=[],this._nodes=[],this._groups=!1,e)switch(this._name=e.name||(e.config&&e.config.name?e.config.name:""),e.class_name){case"AllCNN":case"Sequential":this._loadSequential(e.config,s,"",null,null);break;case"Functional":case"Model":this._loadModel(e.config,s,"",null,null);break;default:throw new keras.Error("'"+e.class_name+"' is not supported.")}else if(s)for(const e of s.keys())if(s.get("",e).length<=6){const n=new keras.Node(t,"Weights",{name:e},[],[],"",s);this._nodes.push(n)}}get name(){return this._name}get groups(){return!!this._groups}get inputs(){return this._inputs}get outputs(){return this._outputs}get nodes(){return this._nodes}_loadModel(t,e,s,n,r){s&&(this._groups=!0);const i=new Map;if(t.layers){for(const e of t.layers)e.name&&(i.has(e.name)||(i.set(e.name,e),e._inputs=[],e._outputs=[]));for(const e of t.layers)if(e.inbound_nodes)for(const t of e.inbound_nodes)for(const s of t){let t=s[0];const n=i.get(t);if(n){const e=s[2];for(0!=e&&(t+=":"+e.toString());e>=n._outputs.length;)n._outputs.push("");n._outputs[e]=t}e._inputs.push(t)}}const a=t.input_layers;if(a)for(let e=0;e<a.length;e++){const s=a[e][0];let r=null;const o=i.get(s);if(o&&"InputLayer"==o.class_name&&(r=this._getInputType(o),i.delete(s)),n&&e<n.length){if(t.layers)for(const r of t.layers)r._inputs&&(r._inputs=r._inputs.map(t=>t===s?n[e]:t))}else this._inputs.push(new keras.Parameter(s,!0,[new keras.Argument(s,r,null)]))}const o=new Map,h=t.output_layers;if(h)for(let t=0;t<h.length;t++){const e=h[t];let s=e[0];const n=i.get(s);let a=!0;if(r&&t<r.length&&(o.set(s,r[t]),s=r[t],a=!1),n){const t=e[2];for(0!=t&&(s+=":"+t.toString());t>=n._outputs.length;)n._outputs.push("");n._outputs[t]=s}a&&this._outputs.push(new keras.Parameter(s,!0,[new keras.Argument(s,null,null)]))}if(t.layers)for(const n of t.layers)i.has(n.name)&&this._loadNode(n,n._inputs,n._outputs,e,s,o)}_loadSequential(t,e,s,n,r){s&&(this._groups=!0);let i=null,a="input",o=0;const h=t.layers?t.layers:t;for(const t of h){let u=o.toString(),c=[a];0==o&&(n&&n.length>0?c=[n[0]]:i=this._getInputType(t)),o++,t.config&&t.config.name&&(u=t.config.name),a=u;let l=[a];o==h.length&&r&&r.length>0&&(l=[r[0]],a=null),this._loadNode(t,c,l,e,s)}n||this._inputs.push(new keras.Parameter("input",!0,[new keras.Argument("input",i,null)])),a&&this._outputs.push(new keras.Parameter(a,!0,[new keras.Argument(a,null,null)]))}_loadNode(t,e,s,n,r,i){const a=t.class_name;switch(a){case"Sequential":{const i=t.name||(t.config?t.config.name:"");this._loadSequential(t.config,n,(r?r+"/":"")+i,e,s);break}case"Model":{const i=t.name||(t.config?t.config.name:"");this._loadModel(t.config,n,(r?r+"/":"")+i,e,s);break}default:{e=e.map(t=>i&&i.has(t)?i.get(t):t);const o=new keras.Node(this._metadata,a,t.config,e,s,r,n);this._nodes.push(o);break}}}_getInputType(t){if(t&&t.config){let e="?",s=[];const n=t.config;return n.dtype&&(e=n.dtype,delete n.dtype),n.batch_input_shape&&(s=n.batch_input_shape.map(t=>null==t?"?":t),delete n.batch_input_shape),new keras.TensorType(e,new keras.TensorShape(s))}return null}},keras.Parameter=class{constructor(t,e,s){this._name=t,this._visible=e,this._arguments=s}get name(){return this._name}get visible(){return this._visible}get arguments(){return this._arguments}},keras.Argument=class{constructor(t,e,s){if("string"!=typeof t)throw new keras.Error("Invalid argument identifier '"+JSON.stringify(t)+"'.");this._name=t,this._type=e||null,this._initializer=s||null}get name(){return this._name}get type(){return this._initializer?this._initializer.type:this._type}get initializer(){return this._initializer}},keras.Node=class{constructor(t,e,s,n,r,i,a){this._group=i||"",this._metadata=t,this._type=e;const o=s&&s.name?s.name:"";this._name=(this._group?this._group+"/":"")+o,this._inputs=[],this._outputs=[],this._attributes=[];let h=[o];if(("Bidirectional"==e||"TimeDistributed"==e)&&s&&s.layer){const t=s.layer;delete s.layer,this._inner=new keras.Node(this._metadata,t.class_name,t.config,[],[],null,null),"Bidirectional"==e&&t.config.name&&(h=[o+"/forward_"+t.config.name,o+"/backward_"+t.config.name],i||(i=o))}const u={};if(a)for(const t of h)for(const e of a.get(i,t))n.push(e.name),u[e.name]=e;if(s)for(const e of Object.keys(s)){const n=s[e];"name"!=e&&null!=n&&this._attributes.push(new keras.Attribute(t.attribute(this.type,e),e,n))}const c=this._metadata.type(this.type),l=this.inner?this.inner.type:null,_=l?this._metadata.type(l):null;let p=0;for(;n.length>0;){let t=!1,r=null,i=!0;if(_&&0!=p)switch(e){case"Bidirectional":{let t=p;_&&_.inputs&&(t<_.inputs.length?r="forward_"+_.inputs[t].name:(t=t-_.inputs.length+1,t<_.inputs.length&&(r="backward_"+_.inputs[t].name))),i=!1;break}case"TimeDistributed":_&&_.inputs&&p<_.inputs.length&&(r=_.inputs[p].name)}else if(c&&c.inputs&&p<c.inputs.length){const n=c.inputs[p];if(r=n.name,"BatchNormalization"===e&&"gamma"===r&&!1===s.scale){p++;continue}i=0!=n.visible,"variadic"==c.inputs[p].option&&(t=!0)}const a=(t?n.splice(0,n.length):[n.shift()]).map(t=>new keras.Argument(t,null,u[t]));if(!r&&1==a.length&&a[0].initializer&&a[0].initializer.name)if(1===h.length&&""===h[0])r=a[0].initializer.name;else{const t=a[0].initializer.name.split("/").pop().split(":").shift().split("_"),e=t.pop(),s=t.length>0?[t.pop(),e].join("_"):"";r=new Set(["recurrent_kernel","running_mean","running_std","moving_mean","moving_variance"]).has(s)?s:e}this._inputs.push(new keras.Parameter(r||p.toString(),i,a)),p++}this._outputs=r.map((t,e)=>{const s=c&&c.outputs&&e<c.outputs.length&&c.outputs[e]&&c.outputs[e].name?c.outputs[e].name:e.toString();return new keras.Parameter(s,!0,[new keras.Argument(t,null,null)])})}get type(){return this._type}get metadata(){return this._metadata.type(this._type)}get name(){return this._name}get group(){return this._group}get inputs(){return this._inputs}get outputs(){return this._outputs}get attributes(){return this._attributes}get inner(){return this._inner}},keras.Attribute=class{constructor(t,e,s){switch(this._name=e,this._value=s,"object"==typeof s&&s.class_name&&s.config&&(this._value=keras.Attribute._convert(s)),e){case"trainable":this._type="boolean",this._visible=!1;break;case"dtype":this._visible=!1;break;default:t&&(t.type&&(this._type=t.type),(Object.prototype.hasOwnProperty.call(t,"visible")&&!t.visible||Object.prototype.hasOwnProperty.call(t,"default")&&keras.Attribute._isEquivalent(t.default,s))&&(this._visible=!1))}}get name(){return this._name}get type(){return this._type}get value(){return this._value}get visible(){return 0!=this._visible}static _convert(t){if(Array.isArray(t)||t!==Object(t))return t;const e={};t.class_name&&(e.__type__=t.class_name);for(const s of Object.keys(t.config))e[s]=keras.Attribute._convert(t.config[s]);return e}static _isEquivalent(t,e){if(t===e)return 0!==t||1/t==1/e;if(null==t||null==e)return!1;if(t!=t)return e!=e;const s=typeof t;if("function"!==s&&"object"!==s&&"object"!=typeof e)return!1;const n=toString.call(t);if(n!==toString.call(e))return!1;switch(n){case"[object RegExp]":case"[object String]":return""+t==""+e;case"[object Number]":return+t!=+t?+e!=+e:0==+t?1/+t==1/e:+t==+e;case"[object Date]":case"[object Boolean]":return+t==+e;case"[object Array]":{let s=t.length;if(s!==e.length)return!1;for(;s--;)if(!keras.Attribute._isEquivalent(t[s],e[s]))return!1;return!0}}const r=Object.keys(t);let i=r.length;if(Object.keys(e).length!=i)return!1;for(;i--;){const s=r[i];if(!Object.prototype.hasOwnProperty.call(e,s)||!keras.Attribute._isEquivalent(t[s],e[s]))return!1}return!0}},keras.Tensor=class{constructor(t,e,s,n,r,i){this._name=t,this._type=new keras.TensorType(e,new keras.TensorShape(s)),this._littleEndian=n,this._data=r,this._reference=i}get kind(){return"Weights"}get name(){return this._name}get type(){return this._type}get reference(){return this._reference}get state(){return this._context().state}get value(){const t=this._context();return t.state?null:(t.limit=Number.MAX_SAFE_INTEGER,this._decode(t,0))}toString(){const t=this._context();if(t.state)return"";t.limit=1e4;const e=this._decode(t,0);return keras.Tensor._stringify(e,"","    ")}_context(){const t={index:0,count:0,state:null};if(this._reference)return t.state="Tensor reference not implemented.",t;if(!this._data)return t.state="Tensor data is empty.",t;switch(this._type.dataType){case"boolean":case"float16":case"float32":case"float64":case"uint8":case"int64":t.dataType=this._type.dataType,t.data=new DataView(this._data.buffer,this._data.byteOffset,this._data.byteLength),t.littleEndian=this._littleEndian;break;case"string":t.dataType=this._type.dataType,t.data=this._data;break;default:t.state="Tensor data type is not supported."}return t.shape=this._type.shape.dimensions,t}_decode(t,e){const s=0!==t.shape.length?t.shape:[1],n=[],r=s[e],i=t.littleEndian;if(e==s.length-1)for(let e=0;e<r;e++){if(t.count>t.limit)return n.push(null),n;switch(t.dataType){case"float16":n.push(t.data.getFloat16(t.index,i)),t.index+=2;break;case"float32":n.push(t.data.getFloat32(t.index,i)),t.index+=4;break;case"float64":n.push(t.data.getFloat64(t.index,i)),t.index+=8;break;case"boolean":n.push(0!==t.data.getInt8(t.index)),t.index+=1;break;case"uint8":n.push(t.data.getUint8(t.index)),t.index+=1;break;case"int64":n.push(new long.Long(t.data.getUint32(t.index+(i?0:4),i),t.data.getUint32(t.index+ +(i?4:0),i),!1)),t.index+=8;break;case"string":n.push(t.data[t.index]),t.index++}t.count++}else for(let s=0;s<r;s++){if(t.count>t.limit)return n.push(null),n;n.push(this._decode(t,e+1))}return 0==t.shape.length?n[0]:n}static _stringify(t,e,s){if(Array.isArray(t)){const n=[];n.push(e+"[");const r=t.map(t=>keras.Tensor._stringify(t,e+s,s));return r.length>0&&n.push(r.join(",\n")),n.push(e+"]"),n.join("\n")}return null===t?e+"...":"string"==typeof t?e+'"'+t+'"':t==1/0?e+"Infinity":t==-1/0?e+"-Infinity":isNaN(t)?e+"NaN":e+t.toString()}},keras.TensorType=class{constructor(t,e){this._dataType=t,this._shape=e}get dataType(){return this._dataType}get shape(){return this._shape}toString(){return this._dataType+this._shape.toString()}},keras.TensorShape=class{constructor(t){this._dimensions=t}get dimensions(){return this._dimensions}toString(){return this._dimensions?"["+this._dimensions.map(t=>t.toString()).join(",")+"]":""}},keras.Metadata=class{static open(t){return keras.Metadata._metadata?Promise.resolve(keras.Metadata._metadata):t.request(null,"keras-metadata.json","utf-8").then(t=>(keras.Metadata._metadata=new keras.Metadata(t),keras.Metadata._metadata)).catch(()=>(keras.Metadata._metadata=new keras.Metadata(null),keras.Metadata._metadatas))}constructor(t){if(this._map=new Map,this._attributeCache=new Map,t){const e=JSON.parse(t);if(e)for(const t of e)t.name&&t.schema&&(t.schema.name=t.name,this._map.set(t.name,t.schema))}}type(t){return this._map.get(t)}attribute(t,e){const s=t+":"+e;if(!this._attributeCache.has(s)){const e=this.type(t);if(e&&e.attributes&&e.attributes.length>0)for(const s of e.attributes)this._attributeCache.set(t+":"+s.name,s);this._attributeCache.has(s)||this._attributeCache.set(s,null)}return this._attributeCache.get(s)}},keras.Group=class{constructor(t){this._group=t}attribute(t){let e=this._group.attribute(t);if(!e&&this._group.attribute(t+"0")){let s=0;for(e=[];;){const n=this._group.attribute(t+s.toString());if(!n)break;e=e.concat(n),s++}}return e}group(t){const e=this._group.group(t);return e?new keras.Group(e):null}get value(){return this._group.value}},keras.JsonParser=class{static parse(t){if(t&&-1!==t.indexOf("NaN"))try{return JSON.parse(t)}catch(e){try{return new keras.JsonParser(t)._read()}catch(t){}}return JSON.parse(t)}constructor(t){this._text=t,this._position=0,this._ch=" ",this._escape={'"':'"',"\\":"\\","/":"/",b:"\b",f:"\f",n:"\n",r:"\r",t:"\t"}}_read(){const t=this._value();return this._whitespace(),this._ch&&this._error("Syntax error"),t}_next(){return this._ch=this._text.charAt(this._position++)}_expect(t){for(let e=0;e<t.length;e++)t[e]!==this._ch&&this._error("Expected '"+t[e]+"' instead of '"+this._ch+"'"),this._ch=this._text.charAt(this._position++)}_whitespace(){for(;this._ch&&this._ch<=" ";)this._next()}_number(){let t="";if("-"===this._ch&&(t="-",this._expect("-")),"I"===this._ch)return this._expect("Infinity"),-1/0;for(;this._ch>="0"&&this._ch<="9";)t+=this._ch,this._next();if("."===this._ch)for(t+=".";this._next()&&this._ch>="0"&&this._ch<="9";)t+=this._ch;if("e"===this._ch||"E"===this._ch)for(t+=this._ch,this._next(),"-"!==this._ch&&"+"!==this._ch||(t+=this._ch,this._next());this._ch>="0"&&this._ch<="9";)t+=this._ch,this._next();return+t}_string(){let t,e,s,n="";if('"'===this._ch)for(;this._next();){if('"'===this._ch)return this._next(),n;if("\\"===this._ch)if(this._next(),"u"===this._ch){for(s=0,e=0;e<4&&(t=parseInt(this._next(),16),isFinite(t));e++)s=16*s+t;n+=String.fromCharCode(s)}else{if(!this._escape[this._ch])break;n+=this._escape[this._ch]}else n+=this._ch}this._error("Invalid string")}_literal(){switch(this._ch){case"t":return this._expect("true"),!0;case"f":return this._expect("false"),!1;case"n":return this._expect("null"),null;case"N":return this._expect("NaN"),NaN;case"I":return this._expect("Infinity"),1/0}this._error("Unexpected '"+this._ch+"'")}_array(){const t=[];if("["===this._ch){if(this._expect("["),this._whitespace(),"]"===this._ch)return this._expect("]"),t;for(;this._ch;){if(t.push(this._value()),this._whitespace(),"]"===this._ch)return this._expect("]"),t;this._expect(","),this._whitespace()}}this._error("Invalid array")}_object(){let t;const e={};if("{"===this._ch){if(this._expect("{"),this._whitespace(),"}"===this._ch)return this._expect("}"),e;for(;this._ch;){if(t=this._string(),this._whitespace(),this._expect(":"),Object.hasOwnProperty.call(e,t)&&this._error('Duplicate key "'+t+'"'),e[t]=this._value(),this._whitespace(),"}"===this._ch)return this._expect("}"),e;this._expect(","),this._whitespace()}}this._error("Invalid object")}_value(){switch(this._whitespace(),this._ch){case"{":return this._object();case"[":return this._array();case'"':return this._string();case"-":return this._number();default:return this._ch>="0"&&this._ch<="9"?this._number():this._literal()}}_error(t){throw new Error(t+" at "+this._position+".")}},keras.Weights=class{constructor(){this._map=new Map}add(t,e){this._map.has(t)||this._map.set(t,[]),this._map.get(t).push(e)}get(t,e){if(t){const s=this._map.get(t.split("/").shift());if(s){const n=s.filter(t=>t.name.startsWith(e+"/"));if(n.length>0)return n;const r=s.filter(s=>s.name.startsWith(t+"/"+e+"/"));if(r.length>0)return r}}else{const s=this._map.get(e);if(s&&s.length>0)return s;const n=this._map.get("");if(n&&n.length>0){const s=n.filter(s=>s.name.startsWith((t?t+"/":"")+e+"/"));if(s.length>0)return s}}return[]}keys(){return this._map.keys()}},keras.Error=class extends Error{constructor(t){super(t),this.name="Error loading Keras model."}},"undefined"!=typeof module&&"object"==typeof module.exports&&(module.exports.ModelFactory=keras.ModelFactory);